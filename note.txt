using click to create simple cli

accept prompt from user . it can be option for now

#using uv loadd uv and run 
uv run --env-file .env main.py 

using .env file to store API_KEY

#
uv add python-dotenv

-----phase 2 -----
- capture response json from server to StreamEvent Type

ChatCompletion(id='gen-1768768832-jz7wiilcnR65ITI0xi2G', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It lo
oks like you might have sent an incomplete message or a placeholder ("test"). Could you clarify or provide more details about what you\'d like to discuss or ask? I
\'m happy to help with any questions or topics you have in mind!', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None, reasoning=None), native_finish_reason='stop')], created=1768768832, model='mistralai/devstral-2512:free', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=49, prompt_tokens=4, total_tokens=53, completion_tokens_details=CompletionTokensDetails(accepted_prediction
_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0), 
cost=0, is_byok=False, cost_details={'upstream_inference_cost': 0, 'upstream_inference_prompt_cost': 0, 'upstream_inference_completions_cost': 0}), provider='Mistral')

display completion in json:

{
  "id": "gen-1768770650-7qyrwNzJz6edDcHKeGCK",
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "logprobs": null,
      "message": {
        "content": "It looks like you might have sent \"test\" to check if the system is working. If you have any questions or need assistance with something speci
fic, feel free to ask! \ud83d\ude0a\n\nFor example:\n- **\"How do I solve this math problem?\"**\n- **\"Can you explain AI in simple terms?\"**\n- **\"What\u2019s 
the weather like today?\"**",
        "refusal": null,
        "role": "assistant",
        "annotations": null,
        "audio": null,
        "function_call": null,
        "tool_calls": null,
        "reasoning": null
      },
      "native_finish_reason": "stop"
    }
  ],
  "created": 1768770651,
  "model": "mistralai/devstral-2512:free",
  "object": "chat.completion",
  "service_tier": null,
  "system_fingerprint": null,
  "usage": {
    "completion_tokens": 75,
    "prompt_tokens": 4,
    "total_tokens": 79,
    "completion_tokens_details": {
      "accepted_prediction_tokens": null,
      "audio_tokens": null,
      "reasoning_tokens": 0,
      "rejected_prediction_tokens": null
    },
    "prompt_tokens_details": {
      "audio_tokens": 0,
      "cached_tokens": 0
    },
    "cost": 0,
    "is_byok": false,
    "cost_details": {
      "upstream_inference_cost": 0,
      "upstream_inference_prompt_cost": 0,
      "upstream_inference_completions_cost": 0
    }
  },
  "provider": "Mistral"
}





